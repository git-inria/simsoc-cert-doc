\documentclass[a4paper, 11pt]{article}

%\usepackage[english, francais]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\usepackage{calc,array,alltt}
\usepackage{url}

\usepackage{tikz}
\usepackage{xcolor}

%\usepackage{xltxtra}
\usepackage{xspace}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}

%\usepackage{latexsym}
%\usepackage{graphicx}
%\usepackage{multirow}

%\usepackage{enumerate}
\usepackage{float}
%\ifhevea\setboolean{footer}{false}\fi


% \newenvironment{fontsans}
%   {\begin{divstyle}{fontsans}}
%   {\end{divstyle}}


\newenvironment{bash}
  {%\selectlanguage{english} 
   \begin{alltt}
   \footnotesize}
  {\end{alltt} %\selectlanguage{francais}
  }
\newenvironment{coq}
  {%\selectlanguage{english} 
   \begin{alltt}
   \footnotesize} %% 8.3pl2 (April 2011)
  {\end{alltt} %\selectlanguage{francais}
  }
\newenvironment{ml}
  {%\selectlanguage{english} 
   \begin{alltt}
   \footnotesize} %% 3.12.1
  {\end{alltt} %\selectlanguage{francais}
  }

\newenvironment{humC}
  {%\selectlanguage{english}
   \begin{alltt}
   \footnotesize}
  {\end{alltt} %\selectlanguage{francais}
  }

\newenvironment{fontsans}
  {}
  {}

%\newcommand{\ML}[1]{$\text{#1}^{ml}$}
%\newcommand{\COQ}[1]{$\text{#1}^{coq}$}

\newcommand{\ML}[1]{#1 ML}
\newcommand{\COQ}[1]{#1 Coq}

\newcommand{\gcc}{GCC 4.5.2\xspace}
\newcommand{\compcert}{CompCert 1.9\xspace}
\newcommand{\ccert}{CompCert\xspace}
\newcommand{\ocaml}{OCaml 3.12.1\xspace}
\newcommand{\coqc}{Coq 8.3pl2\xspace}
\newcommand{\coqv}{14161}
\newcommand{\newrelease}{A first public release will be soon available}

\newcommand{\gccSL}{$_{\tt gcc}{\tt simlight}$\xspace}
\newcommand{\cSL}{$_{\tt compcert}{\tt simlight}$\xspace}
\newcommand{\aSL}{$_{\tt asm}{\tt simlight}$\xspace} %\overset{\checkmark}{\leadsto}
%\newcommand{\lSL}{$_{\tt preserved}{\tt simlight}$\xspace}
\newcommand{\lSL}{$_{\lambda^\leadsto}{\tt simlight}$\xspace}
\newcommand{\SL}{{\tt coq$\relbar$simlight}\xspace}
\newcommand{\simgen}{{\tt simgen}\xspace}
\newcommand{\CCasm}{$_{\tt compcert}{\tt ASM}$\xspace}
\newcommand{\C}{$_{\tt compcert}{\tt C}$\xspace}
\newcommand{\gccC}{$_{\tt gcc}{\tt C}$\xspace}
\newcommand{\hC}{$_{\tt human}{\tt C}$\xspace}
\newcommand{\aC}{$_{\tt asm}{\tt C}$\xspace}
%\newcommand{\lC}{$_{\tt preserved}{\tt C}$\xspace}
\newcommand{\lC}{$_{\lambda^\leadsto}{\tt C}$\xspace}
\newcommand{\ps}{{\tt pseudocode}\xspace}
\newcommand{\dec}{{\tt decoder}\xspace}
\newcommand{\outworld}{the outside world\xspace}
\newcommand{\simsoc}{SimSoC\xspace}
\newcommand{\SScert}{SimSoC-Cert\xspace}
\newcommand{\coqkernel}{"The kernel does not recognize yet that a parameter can be instantiated by an inductive type."}

\newtheorem{ex}{Example}[subsection]
\newtheorem*{note}{Notation}
\newtheorem{fact}{Fact}

\author{Frédéric Tuong}
\title{Fast certified simulation with the SH4 model}
\date{November 2010 - October 2011}

\begin{document}

\maketitle
\tableofcontents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

%% %%%%%%%%%%%%%%%%%%%%%%%% french
%% La stabilité d'un système embarqué repose sur le bon fonctionnement de ses composants. Pour effectuer des tests complets sur l'ensemble, avant la phase de fabrication matérielle, les concepteurs s'intéressent à avoir des logiciels simulant le système, prenant en entré un binaire exécutable quelconque. Le projet \simsoc vise à mettre à la disposition des développeurs un tel simulateur, ce dernier étant organisé en différents composants modulaires. Parmi les composants d'un système, le processeur est un élément important aussi bien lors de sa fabrication que lors de sa simulation. D'une part les erreurs de conception engendrent un coût élevé, et d'autre part la durée d'un programme est liée aux instructions du processeur. Pour obtenir une machine sûre, il y a donc une nécessité de travailler avec les simulateurs. Néanmoins, comment garantir qu'un simulateur se comporte \emph{exactement} comme une machine ?
%% Le but de \SScert est justement de répondre à cette question, en proposant de certifier chacune des parties de \simsoc. S'agissant d'un projet ambitieux et d'envergure, en commençant par la correction du processeur, nous nous concentrons en premier sur le c\oe ur du simulateur. 

%% Plus particulièrement, \SScert contient un simulateur du processeur ARMv6 écrit en Coq. Pour le modéliser et l'intégrer au sein de Coq, il a été nécessaire de construire un modèle formel du processeur, ce modèle nous informe précisément sur la sémantique de chaque instruction. 
%% Notre travail s'intéresse à l'importation d'un autre type de processeur au projet \SScert : il s'agit du processeur SH4. Comme pour l'ARM, nous montrons à la section [?] comment obtenir un modèle mathématique du SH4 à partir de son manuel de référence.
%% %%%%%%%%%%%%%%%%%%%%%%%%
Stability of embedded systems depends on the good behavior of their components. Before reaching the construction of the final material in factory, exhaustive testing is thus a strong requirement. At the same time, designer tends to be interested in software simulating the global system and taking a real binary as input. The goal of the \simsoc project~\cite{ossc09} is to permit engineers to develop systems with such a tool, it contains a simulator split modularly into several components. Among these components, the processor is an important element to consider not only during the production but also for the simulation. On one side, errors of conception are susceptible to have a high economical impact. On the other side, the time execution of an algorithm depends on the processor's optimizations. To get a safe system, the need to work with simulators are then going increasingly. However, how can we guarantee the \emph{exact} behavior between simulator and embedded systems ? 
The goal of \SScert is precisely to answer this question, we propose to certify each part of \simsoc. Being an ambitious project, we plan to begin with the correction of the processor, this targets directly the heart of the simulator.

In particular, \SScert contains a simulator of the ARMv6 written in Coq~\cite{arm6refman, arm}. The language Coq is a system which builds a constructive proof from a specification by looking at the programmer's hints~\cite{Coq:manual}. One common application is the extraction procedure which translates the proof, considered as a $\lambda$-term, to another functional language like OCaml~\cite{OCaml}. To model and integrate the simulator within Coq, it was necessary to build a formal model of the processor, this model informs us precisely on the semantics of each instruction.
Our work focuses on the importation of another type of processor into the \SScert project : it is the SH4 processor~\cite{sh4refman}. 

As for ARM, we show at section~\ref{s:simu_sh4} how to get a mathematical model of SH from his reference manual. Section~\ref{s:fast_certi} presents our first step into the certification problem. Our work begins now with some general definitions in section~\ref{s:certi_sim}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Certified simulation}
\label{s:certi_sim}

This section introduces the concept of software simulation by explaining how simulations work and what informations we need to import from the constructor manual. For the following, we restrict our attention to the simulation of the processor as it is the first and existing component studied in \SScert. We also present the current state of \simsoc and \SScert, and explain at the end the principle and goal of the \ccert compiler.

\begin{note}
For the following, we will use the symbols
\begin{itemize}
\item \hC to designate an arbitrary sequence of character, 
\item \gccC for programs compiled successfully with \gcc~\cite{gcc} (tested at least one time),
\item \C for programs for which a generated \ccert C file~\cite{Leroy-Compcert-CACM} can be successfully dumped (tested at least one time), in general before the end of the compilation. For a demonstration with \compcert, see the option \verb|-dc|.
\end{itemize}
\end{note}

\subsection{Principle of a processor simulator}
%% %%%%%%%%%%%%%%%%%%%%%%%% french
%% Les spécifications du SH4 sont fournies dans un document disponible au format PDF et le fonctionnement de chaque instruction est décrit en langage naturel. Notre but est de construire un modèle mathématique du processeur à partir de cette documentation, un modèle qui soit le plus proche possible de la sémantique informelle fournie par le constructeur.

%% Pour l'ARM, un travail similaire a été accompli en extrayant les informations du manuel de référence avec un programme, et après une phase de correction préliminaire sur la syntaxe.

%% De manière générale, un simulateur de processeur a essentiellement besoin de deux informations pour fonctionner.
%% \begin{itemize}
%% \item La première est celle décrivant le comportement de chaque instruction, appelé ``pseudocode''. Chaque instruction du processeur (ADD, CPY, MOV ...) est précisément composé d'une séquence de primitives bas niveau : copie ou affectation de registres, opérations d'accès à la mémoire... Parfois, le manuel de référence précise que le comportement n'est pas défini ou incertain dans certaines situations (``unpredictable'' pour l'ARM, ``Appendix B'' pour SH4).
%% \item La deuxième information dirige la phase du ``décodage'' des instructions. Étant donné un mot binaire de taille fixe, il s'agit de retrouver à partir de ce mot l'instruction qui lui est associée (pour l'exécuter), et quels sont éventuellement ses arguments. À priori, il pourrait y avoir une ambiguïté sur la recherche d'une instruction correspondant à un mot donné, on pourrait trouver plusieurs instructions candidates pour un mot. L'ordre des instructions à tester en premier a également une importance. Normalement, les indications disponibles dans les manuels sont suffisament clairs pour éviter ces ambiguïtés.
%% %Chaque instruction s'accompagnant d'un motif prédéfini dans le manuel, cette recherche s'effectue en les testant un par un jusqu'à l'obtention d'un succès. Cependant, l'ordre des tests peut être important
%% %Dans le manuel de référence, ces indications s'obtiennent facilement, car rassemblées sous la forme d'un tableau pour chaque instruction.
%% \end{itemize}
%% %%%%%%%%%%%%%%%%%%%%%%%%


Generally, a processor simulator basically needs two informations in order to accomplish his task.
\begin{itemize}
\item The ``pseudocode'' describes the behavior of each instruction. Each processor instruction (add, cpy, mov ...) are precisely composed of sequences of low-level primitives : copy, affectation of register or access operation to the memory... The unknown or uncertainty behavior in some situations are in general stated in the reference manual (for example, ``UNPREDICTABLE'' case in instruction for the ARM, the same is described in Appendix B for the SH). In any case, specified or not, when importing the semantics to some formal model, we will be forced to explicitly specify the meaning of all the unknown behavior.
\item The ``decoder'' pilots the association from binary word to instruction. Given a binary word of fixed size, the goal is to retrieve from this word the instruction associated to the word, in order to execute it, as well as his potential arguments. 
The correction of the decoder is as important as the pseudocode for a good simulation. We want for example to be sure that there is only one instruction associated to a word.
\end{itemize}
Providing these two informations, we are able to model a simple simulator in Coq\footnote{Coq being a strongly normalizing language, the simulation is performed within a fixed number of recursive step.}. This is exactly what the \SScert project contains.

\subsection{The \SScert project}
The goal of \SScert~\footnote{\newrelease~\cite{urlsscert}.} is to certify \simsoc~\cite{arm}, because its large part is written in C++~\cite{ossc09} and currently we are not sure about the safety of our C++ compiler used. However, for the processor simulator, it is possible to abstract most of the surrounding C++ features. We call then \gccSL the \gccC part restricted to the component which simulates the processor. Because we are currently in the same unpredictable situation with a \gccC program, we want to have a formal proof that our \gccC code behaves correctly. But what does ``formal proof'' mean in the case we are comparing a virtual software and a real hardware ? Even if the hardware is produced with the help of the computer, its specification depends directly on the format of the documentation the constructor gives. For our subject of processor certification, the processor documentation is generally available in raw text. For example, specifications of the SH4 are published in a PDF document and inside, the behavior of each instruction are described in natural language. Our goal is to build a mathematical model of the processor from the processor documentation, one which is as closer as possible to the one furnished by the constructor. Then, understanding this definition of ``formal proof'', the \gccC code behind \gccSL needs to behave correctly with respect to the semantic of this mathematical model. Note that to be strict, because the manual can contains some erroneous specifications, further validation tests with the real hardware will remain to be performed in the final end, in order to obtain an observationally equivalent behavior with the simulator.

\paragraph{Related work}
A formalization of the ARMv7 processor is reported in~\cite{conf/itp/FoxM10}. The ARMv7 model has been constructed manually using the proof assistant HOL4, with monad as combinator for semantic functions. 
We are interested to automatically generate a Coq model, which aim to be as understandable as possible to the manual of reference. We will show later how coercions and notations in Coq are advantages for readability, but we will also notice some limitations of their use for a large proof project. Organizing the project modularly in Coq will also permit us to integrate simultaneously ARMv6 and SH4 in a generic simulator, and gain an easier interaction with \ccert.

\subsubsection{The simulator \SL and the toolkit \simgen}
\label{s:simgendef}
Now, before considering the SH, let us look at what we already have in \simsoc and \SScert. On one side, there is \gccSL. On the other side, a mathematical model in Coq had automatically been built for the ARM~\cite{arm} and thus a special simulator has especially been created to integrate as well as to test the model : \SL.
The behavior of \gccSL and \SL, which have both been manually designed, is intentionally the same : for compiling, these two simulators need the ARM manual specification (in their respective language).

Therefore, \simgen, which is also part of \SScert, has especially been created for the importation of the ARM manual.
To illustrate this, we present here the contents of \verb|pseudocode.v| and \verb|decoder.v|, automatically generated by the toolkit.

\subsubsection{The ARMv6 {\tt pseudocode.v}}
\label{s:oldarm}
This file contains the semantics of all the instructions written in the Coq language. Each instruction from the manual of reference is translated in a similar Coq function, called ``\verb|..._step|'' function. 
Furthermore, as for modularity the generation of the {\tt decoder.v} is currently done in a separate way than the {\tt pseudocode.v}, we create an inductive type $inst$ containing exactly a constructor for each ``\verb|..._step|'' function. $inst$ will be useful for interoperability between {\tt pseudocode.v} and {\tt decoder.v}. At the end of {\tt pseudocode.v}, there is a main function $step$ which role is, given a value of type $inst$, to retrieve the corresponding ``\verb|..._step|'' function to run it.

Instructions from the ARMv6 are a bit special. Given a fixed sized word, we usually think about the instruction corresponding to this word, in particular during the decoding phase. But in ARMv6, we need to parameterized our thought one step higher. Indeed, some instructions take as argument a special parameter. This parameter is intended to be specially treated and a preliminary function need to be apply before the real execution of the instruction. This typical case is the \emph{addressing mode}.

Because the ARM manual contains roughly 150~instructions (and about 75 special THUMB instructions), we will sketch an example with just 2 instructions : {\tt A4.1.21 LDM (2)} and {\tt A4.1.81 SMLSLD}. Without entering deeply in details, the reader is invited to have a look at the Coq code (more details in \cite{urlsscert}) or to jump directly to the next section.

\paragraph{The addressing mode case}
  \subparagraph{Type}
According to the ARM manual, there are 5 special modes.
\begin{coq}
Inductive mode1 : Type := [...].
Inductive mode2 : Type := [...].
Inductive mode3 : Type := [...].
Inductive mode4 : Type :=
  | M4\_Incr\_after         [...] 
  | M4\_Incr\_before        [...]
  | M4\_Decr\_after         [...]
  | M4\_Decr\_before        [...].
Inductive mode5 : Type := [...].  
\end{coq}
(to simplify, we have replaced some non-relevant informations by ``\verb|[...]|'')
  \subparagraph{Definition}
For each constructor regrouped above, an executing function associated is furnished.
\begin{coq}
[...]
(* A5.4.2 Load and Store Multiple - Increment after *)
Definition M4_Incr_after_step s0 W cond n r [...] : result * word * word :=
  let start_address := (reg_content s0 n) in
  let end_address := (sub [...]) in
  let r := block (
    (fun loc b st => if_then [...]
      (fun loc b st => set_reg n (add [...]) loc b st) loc b st) ::
    nil) nil true s0 in
    (r, start_address, end_address).
[...]
\end{coq}
  \subparagraph{Correspondence between the type and definition}
Finally, this simple part illustrates the symmetry between type and definitions. 
\begin{coq}
Definition mode1\_step (s0 : state) (m : mode1) := [...].
Definition mode2\_step (s0 : state) (m : mode2) := [...].
Definition mode3\_step (s0 : state) (m : mode3) := [...].
Definition mode4\_step (s0 : state) (m : mode4) :=
  match m with
    | M4\_Incr\_after W c n r => M4\_Incr\_after\_step s0 W c n r
    | M4\_Incr\_before W c n r => M4\_Incr\_before\_step s0 W c n r
    | M4\_Decr\_after W c n r => M4\_Decr\_after\_step s0 W c n r
    | M4\_Decr\_before W c n r => M4\_Decr\_before\_step s0 W c n r
  end.
Definition mode5\_step (s0 : state) (m : mode5) := [...].
\end{coq}
Note that along the pattern matching, the state $s0$ is always present at the right hand side. Even if semantically we understand this as a monadic construction~\cite{peyton-jones-wadler-93, peyton-jones-tackling-09}, we will see in the SH part how to rewrite the whole to explicitly hide $s0$.
\paragraph{The instruction case}
Here, the same structure as the \emph{addressing mode} is done for the \emph{instruction} case, i.e. we define a structure for type, definitions, and at the end, we relate them with a main correspondence function.
  \subparagraph{Type}
\begin{coq}
Inductive inst : Type := 
[...]
  | LDM2 (m_ : mode4) (cond : opcode) (register_list : word) 
[...]
  | SMLSLD (X : bool) (cond : opcode) 
      (dHi : regnum) (dLo : regnum) (m : regnum) (s : regnum)
[...].
\end{coq}
Notice the additional parameter $m\_$ of {\tt LDM2}, which contains the specification of the addressing mode.
  \subparagraph{Definitions}
\begin{coq}
[...]
(* A4.1.21 LDM (2) *)
Definition LDM2_step (s0 : state) cond r s [...] : result :=
  if_then (ConditionPassed s0 cond)
    (fun loc b st => block (
      (fun loc b st => update_loc n0 (*address*) s loc b st) ::
      (fun loc b st => loop 0 n14 (fun i => 
        if_then (zeq (r[i]) 1)
          (fun loc b st => block (
            (fun loc b st => [...] (read st ([...] loc) Word) loc b st) ::
            (fun loc b st => [...] (add ([...] loc) (repr 4)) loc b st) ::
            nil) loc b st)) loc b st) ::
      nil) loc b st) nil true s0.
[...]
(* A4.1.81 SMLSLD *)
Definition SMLSLD_step (s0 : state) X cond dHi dLo m s [...] : result :=
  if_then (ConditionPassed s0 cond)
    (fun loc b st => block (
      (fun loc b st => update_loc n1 (*operand2*) 
        (if zeq X 1 then Rotate_Right [...] else reg_content s0 s) loc b st) ::
      (fun loc b st => update_loc64 n0 (*accvalue*) 
        (or64 ([...] ((*ZeroExtend*)(reg_content st dHi))) [...]) loc b st) ::
      (fun loc b st => update_loc n2 (*product1*) 
        (mul [...] (get_signed_half0 (get_loc n1 (*operand2*) loc))) loc b st) ::
      (fun loc b st => update_loc n3 (*product2*) 
        (mul [...] (get_signed_half1 (get_loc n1 (*operand2*) loc))) loc b st) ::
      (fun loc b st => update_loc64 n4 (*result*) (sub64 (add64 
          (get_loc64 n0 (*accvalue*) loc) 
          (get_loc n2 (*product1*) loc)) 
        (get_loc n3 (*product2*) loc)) loc b st) ::
      (fun loc b st => set_reg dLo (get_lo (get_loc64 n4 (*result*) loc)) loc b st) ::
      (fun loc b st => [...] (get_hi (get_loc64 n4 (*result*) loc)) loc b st) ::
      nil) loc b st) nil true s0.
[...]
\end{coq}
  \subparagraph{Correspondence between the type and definition}
\begin{coq}
Definition step (s0 : state) (i : inst) : result :=
  match i with
[...]
    | LDM2 m_ cond r =>
      match mode4_step s0 m_ with (r, s, end_address) =>
        match r with
          | Ok _ _ s1 => LDM2_step s1 cond r s
          | _ => r
        end
      end
[...]
    | SMLSLD X cond dHi dLo m s => SMLSLD_step s0 X cond dHi dLo m s
[...]
  end.
\end{coq}
In contrast with {\tt SMLSLD\_step}, the execution of {\tt LDM2\_step} is preceded by an extra call to {\tt mode4\_step}.
\subsubsection{The ARMv6 {\tt decoder.v}}
The structure of this file is rather simple. Given a word, we decompose it into a list of raw bits, then a pattern matching is applied to this list. The bits in each clause comes directly from the manual, as well as the instruction associated to each list.
\subsection{The \ccert project}
The goal of \ccert is precisely to transform most of the \hC programs to an assembler program, with a semantic preservation certificate. 

Generally, if the compiler can produce an assembler file from a \hC program, the well behavior at runtime of the assembler produced depends on two facts :
\begin{itemize}
\item how the generated assembler file is interpreted,
\item and the well behavior of the program at \C production time (as well as a heuristically\footnote{Starting from \gccC, there is currently no Coq proof of semantic preservation to \C%, because
. } good translation from \hC to \C).
\end{itemize}
The first point is not very problematic as discussed in~\cite{Leroy-Compcert-CACM} and we will give a short comment later.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Simulation of the SH4}
\label{s:simu_sh4}

The integration of SH4 in \SScert follows the same algorithm as ARMv6. The first step is to transform the raw $string$ of the manual into a more structured type. For the ARM, the transformation from the manual to Coq has precisely crossed a quite structured abstract syntax tree\footnote{The AST is approximatively formed with 400 OCaml words.}. Because the ARM generation to Coq is done from this AST, we plan to fix it as our target for SH. Consequently, we hope the algorithm generating to Coq can be reused rapidly for the SH.

\hspace{1ex}

Besides the target fixed at this advanced AST, we show at the next part how the parsing of the SH manual is performed, as well as another intermediate type which is finally used before getting this AST.


  \subsection{Parsing of the SH4 manual}
%% %%%%%%%%%%%%%%%%%%%%%%%% french
%% Le manuel SH4 contient au total environ 450 pages, la partie où se trouve les informations correspondant au pseudocode et au décodeur occupe une place assez importante, près de la moitié du fichier. Construire directement à la main un modèle en Coq est donc long ou avec risques possibles d'erreurs. De plus, les informations à importer sont à première vue organisées de façon régulière, et il semble donc accessible de les traiter automatiquement avec un programme.
%% %%%%%%%%%%%%%%%%%%%%%%%%
The SH manual totals about 450 pages, informations corresponding to the pseudocode and decoder occupies an important part, approximately the half of the file. Building directly a model at hand in Coq is thus long or with a non negligible risk of errors. 
Furthermore, while reading it briefly, we have been having a strong conjecture that the \hC code specified in the instructions can be easily translated to \gccC. To experiment our intuition, we have planned to use the CIL library~\cite{necula} as type representing the \gccC in OCaml (as \ccert did for the parsing step). Then, starting from the manual considered as a string, the first step was to write the smallest patch possible in order to get a first well-typed CIL AST in OCaml (surrounded by the other extra informations, such as for the decoder...).

The parsing of the decoder informations was merely fast because for each instructions, they are clearly specified in an array. We explains now the process done for the instructions.

\paragraph{Patching phase}

Interesting informations in the SH manual are located at ``section 9, Instruction Descriptions''. It is formed by a preliminary header containing functions specific to floating instructions, followed by a sequence of description of the instructions. 

Corrections needed to bring to the manual are essentially composed of missing symbol ``;'', missing type informations before some parameters and unbounded value encountered. 

For example, the function \verb|LDCRn_BANK| in the part ``9.50, LDC'' uses the unbound variable \verb|Rn_BANK|.  After a search, we finally found that it is a meta abbreviation for \verb|R|$n$\verb|_BANK|, with $n \in [|0;7|]$, as described in the function's comment. Then this special expansion of $n$ has been specially handled by our SH4 parser.

    \paragraph{More confidence by type-checking}
Besides the obtaining of the CIL AST, we think that all the \hC code behind each instructions are predestined to be ultimately executed. Hence, we can extend our test protocol by compiling them with \ccert.

The typing process from the CIL AST to \C has actually permitted us to correct new errors.
\begin{itemize}
\item We have discovered some new misleading types (for instance we introduce manually \verb|bool_of_word| and \verb|nat_of_word| in the definition of \verb|FPSCR_PR| and \verb|FPSCR_FR|).
\item It becomes mandatory to specify the type annotation of undefined functions (e.g. the 9.91 SLEEP instruction use the unbound \verb|Sleep_standby| function name). 
\item The order of function declarations has an importance : like OCaml, permutations are not allowed for functions not specified as recursive. This problem has been resolved by rearranging the order at top-level of SH functions, in general a simple reversing suffices.
% \paragraph{existe-t-il des modifications pour ce cas : pas de 'return' dans le cas de type fonction renvoyant 'void' ? spécifique à simlight ?}
\end{itemize}


  \subsection{Grouping SH4 and ARMv6 into a common pseudocode generator}
The next step after the obtaining of a ML value representing the SH4 manual is its integration in \SScert. To this end, we have performed two modifications : 
\begin{itemize}
\item at the \SL source by adding the model of the SH4 processor (model of the state, particular numbering of register, semantics of remaining undefined functions...),
\item at \simgen to generate the Coq SH4 manual in the same way as what is done for ARMv6.
\end{itemize}
The goal was not only to accomplish these tasks but also to fusion the changes with ARMv6 using modules and functors, to permit future integration of processors.

\hspace{1ex}

Generating the Coq code was rather long but easy, because a lot of factorization was necessary. We give briefly the modifications required in the AST.
\begin{itemize}
\item Unlike the ARM, the parameter of each SH instructions are clearly specified in the pseudocode. We then modified the internal AST to support these argument informations.
\item In term of semantics, there is a specific constructor, namely \verb|return|, presents in the SH pseudocode. It has been represented in the semantic of the Coq code using monadic form.
\item The default case for the \verb|switch| option is also present in several SH instructions, then the necessary changes in the AST has been done.
\end{itemize}
    \subsubsection{$\lambda$-optimization of the Coq manual}
In section~\ref{s:oldarm}, we have seen that the body of the function \verb|LDM2_step| and \verb|SMLSLD_step| are explicitly informative. Indeed, the words \verb|fun loc b st| are for example repeated a lot. However, the purpose of the variable \verb|st| is to carry the transformation on the state, acting like an accumulator. \verb|b| and \verb|loc| are also accumulators but we remark that \verb|b| is just used at a higher function call level, not inside each instruction. So we want to abstract all of them now. Initially, the code present for the ARM was designed and really thought using monadic specifications, but the current shape is currently not entirely satisfactory. Then we think instead, to simplify these accumulators by hiding them at the cost of rearranging the arguments of several functions, in particular by putting all the accumulators at the end.

Additionally, we also notice that the \verb|loc| variable, used to model some local stack for variable, is used frequently even for variable which is affected only once. Indeed, we are attempted to replace them by a native Coq ``\verb|let|'' construct when needed.

\hspace{1ex}

We will explain later that our goal is to prove the well-defined behavior of the Coq simulator, as well as the \gccC simulator. Modifications on the Coq code can thus be considered as superfluous, except for precisely readability of the proof we plan to do. In particular, it is close to some form of compilation to a factorized $\lambda$-code. Without going formally, we are interested to minimize, as possible as it can be, the number of node representing the Coq AST for simplifying the future proof (for example, among the optimizations cited above, one can imagine transforming a {\tt if [...] then f f\_true else f f\_false} into a {\tt f (if [...] then f\_true else f\_false)}).

\hspace{1ex}

Here comes the file obtained after performing some simplifications and rewriting to monadic style. We present the ARMv6 file rather than the SH4 because its manual contains rich examples. In any case, modifications affect both outputs in the same manner (for more details, the reader is invited to see both generated files~\cite{urlsscert}).
\paragraph{The new ARMv6 {\tt pseudocode.v}}
Simplifications are done inside the semantic definition and the correspondence type-definition, in particular declaration for types remains the same.

\hspace{1ex}

We assume below 
\begin{itemize}
\item having defined a notation for vectors as 
\begin{coq}
  Notation "\{\{ a ; .. ; b \}\}" := 
    (Vcons _ a _ .. (Vcons _ b _ (Vnil _)) ..).
\end{coq}
(see the Coq library \verb|Bvector|). In particular, we rely on the type-checker to guess the \verb|nat| associated to each element.
\item having these notations for semantic functions
\begin{coq}
Notation "'<.' loc '.>' A" := (_get_loc (fun loc => A)) 
  (at level 200, A at level 100, loc ident).
Notation "'<' st '>' A" := (_get_st (fun st => A)) 
  (at level 200, A at level 100, st ident).
Notation "'<:' loc st ':>' A" := (<.loc.> <st> A) 
  (at level 200, A at level 100, loc ident, st ident).
Notation "'do_then' A ; B" := (next A B)
  (at level 200 , A at level 100 , B at level 200).
\end{coq}
\verb|_get_loc| and \verb|_get_st| are two new monadic expressions which give access respectively to the accumulator \verb|loc| and \verb|st| in their body.
\verb|next| is like the \verb|bind| operator~\cite{peyton-jones-tackling-09} except that the communicating value is ignored.
\item having a function \verb|_ret| which is like the \verb|return| combinator~\cite{peyton-jones-tackling-09} except that it also returns \verb|true| as a couple with the default value.
\end{itemize}
  \subparagraph{(addressing mode) Definition}
\begin{coq}
[...]
(* A5.4.2 Load and Store Multiple - Increment after *)
Definition M4_Incr_after_step W cond n r [...] : semfun _ := <s0>
  let start_address := reg_content s0 n in
  let end_address := sub [...] in
  do_then [ if_then [...]
       (set_reg n (add [...])) ];
  ret_ \{\{ start_address ; end_address \}\}.
[...]
\end{coq}
Intuitively, each ``mode \verb|..._step|'' function returns a monadic vector (\verb|semfun| being the monadic type) because we want later to perform some uniform treatment for each function and their type need then to be unifiable. This is illustrated below with the introduction of \verb|mode_step|.
\subparagraph{(addressing mode) Correspondence type-definition}
\begin{coq}
Definition mode1\_step (m : mode1) : _ -> semfun unit := mode\_step [...].
[...]
\end{coq}
\verb|mode_step| is a kind of initialization function. In particular, the local stack for local variable are initialized to be empty here. \verb|mode_step| is precisely used in \verb|mode1_step|, \verb|mode2_step|, $\dots$, \verb|mode5_step|.

\subparagraph{(instruction) Definitions}
\begin{coq}
[...]
(* A4.1.21 LDM (2) *)
Definition LDM2_step cond r s [...] : semfun _ := <s0>
  if_then (ConditionPassed s0 cond)
    ([ update_loc n0 (*address*) s
    ; loop 0 n14 (fun i => 
         if_then (zeq (r[i]) 1)
           ([ <:loc st:> [...] (read st ([...] loc) Word)
           ; <.loc.> [...] (add ([...] loc) (repr 4)) ])) ]).
[...]
(* A4.1.81 SMLSLD *)
Definition SMLSLD_step X cond dHi dLo m s : semfun _ := <s0>
  if_then (ConditionPassed s0 cond)
    ([ <st> let operand2 := 
              if zeq X 1 then Rotate_Right [...] else reg_content s0 s in
    let accvalue := or64 ([...] ((*ZeroExtend*)(reg_content st dHi))) [...] in
    let product1 := mul [...] (get_signed_half0 operand2) in
    let product2 := mul [...] (get_signed_half1 operand2) in
    let result := sub64 (add64 accvalue product1) product2 in
    [ set_reg dLo (get_lo result)
      ; <st> [...] (get_hi result) ]]).
[...]
\end{coq}
As for \verb|M4_Incr_after_step|, the state parameter \verb|st| is encapsulated in the monadic type \verb|semfun|. The underscore in the return type \verb|semfun _| is present not only to let the type-checker deduce the real answer but also the part corresponding to the generation of this type information in \simgen are merged for \verb|M4_Incr_after_step| and all the \verb|..._step|. In particular, the type behind the \verb|_| is not necessarily the same in the both cases.

In the body, \simgen detects automatically the use of \verb|st| or \verb|loc|. Hence it adds the corresponding notation when needed.
\subparagraph{(instruction) Correspondence type-definition}
\begin{coq}
Definition step (i : inst) : semfun unit :=
  do_then conjure_up_true;
  match i with
[...]
    | LDM2 m_ cond r => mode4_step m_ (fun s end_adr => LDM2_step cond r s)
[...]
    | SMLSLD X cond dHi dLo m s => SMLSLD_step X cond dHi dLo m s
[...]
  end.
\end{coq}
The parameter \verb|st| having been moved to the end, we observe a certain symmetry in the shape of correspondence between definition and type. Here, the symmetry is clearly highlighted in all the ``mode \verb|..._step|'' function and even in the above \verb|step|, except for specific instructions such as \verb|LDM2| where a specific treatment for addressing mode remains to be done. However, the \verb|mode4_step| call becomes simplified compared to the previous \verb|step| in section~\ref{s:oldarm}.
\subsubsection{Discussions}

\paragraph{Limit of the Coq generation}
The packing system of module as a first-class value in \ocaml encourages us to organize rapidly the code for ARMv6 and SH4. The counterpart is the explicit typing required of the module contents. The typing information becomes also mandatory in Coq, when sometimes we need to explicitly redefine by hand some record\footnote{We frequently encounter the message : \coqkernel}. Finally, we sometimes have erroneous OCaml extracted files with some Coq type containing a singleton constructor (more details in the appendix \ref{s:appendix_singl}).

\hspace{1ex}

We can wonder if the manual we generate can be written in a total monadic style~\cite{conf/itp/FoxM10}. For example, the \verb|if_then| constructor can become a \verb|if_then| monadic combinator, as well as the several encountered \verb|ConditionPassed|. Then we hope one can rewrite \\
``{\tt <s0> if\_then (ConditionPassed s0 cond) [...]}'' as \\
 ``{\tt if\_then (ConditionPassed\_s0 cond) [...]}'' annihilating the need to use \verb|_get_loc| and \verb|_get_st|\footnote{Because the first call to {\tt \_get\_st} at the start affects the variable {\tt s0}, this variable needs to be treated carefully, in a monadic reference for example, if we delete {\tt \_get\_st}.}. However we are in front of a difficulty. Indeed, the automatically generated Coq manual uses extensively the coercion facility, for instance to consider a boolean value as a word (or integer)~\cite{arm}. Hence, the Coq code is finally very close to the original \gccC code from the manual. Because sometimes the \verb|st| is deeply embedded in arithmetical expressions, we 
have a problem of coercion at higher-order level. Currently an
expression like
\verb|zeq 1 true| is implicitly translated to \verb|zeq 1 (Z_of_bool true)|
with \verb|zeq : Z -> Z -> bool|.
If now, we have a \verb|zeq_| of type \verb|semfun Z -> semfun Z -> semfun bool|,
this is not well-typed :
\verb|zeq_ (ret 1) (ret true)|,
unless we give explicitly the hint annotation
\verb|zeq_ (ret (1 : Z)) (ret (true : Z))|.
Note that for readability we can also introduce a notation and write
something similar to \verb| zeq_ { 1 } { true }|.

Because the final goal of the manual is also the proof, we can now wonder if it is finally convenient to perform some proof with notations rather than concrete definitions.

\paragraph{Performance}
Currently, the generation of the SH4 manual is complete except for floating and MMU instructions. The Coq ARMv6 manual contains 148 instruction cases (without THUMB) and 204 for the SH4 (by considering also the expansing of the \verb|R|$n$\verb|_BANK|) but the SH {\tt pseudocode.v} file size occupies only 2/3 of the one of ARM. The SH output for instructions is very simple because it does not contain precomputation for addressing mode. Consequently, the correspondence between type and definition is completely symmetric, for example we can easily delete the type and replace them by their equivalent ``\verb|..._step|'' function.

The compilation of SH {\tt decoder.v} is long~: about 30s on a recent computer while for the ARM we get only 4s with the same machine. Its time is spent mostly on the pattern-matching for retrieving an instruction given a word, the non redundancy detection may be a possible cause of the long analysis. In particular, by performing some sorting on the clause, we get a better compilation time.

\hspace{1ex}

In any case, these results is susceptible to be changed, because we mainly need to be sure that the SH model is correct with respect to the hardware, so further modifications on the model is susceptible to be brought.

\paragraph{Correction of the simplification}
Inside each instructions in the manual, we suspect there is at most one access to modify the environment per line. It concerns the storing of value inside memory or to the local stack \verb|loc|. We have also encountered several read of mutable variable in one line, which does not seem to conflict with storing at the same time. Because the Coq manual may changed in the future (if we discover some erroneous specifications), the current correctness guarantee relies first on its good type-checking.
Note that for SH4, there is a specific instruction \verb|Read_Byte| to access a particular location. We found convenient to set the type of this function to a monadic one, i.e. \verb|word -> semfun word| as well as its companion \verb|Write_Byte|. Because \verb|Read_Byte| can be present several times in a line, it was necessary to coat it with an explicit call to \verb|bind|. Then the computation ``sequentially'' continues inside the body of \verb|bind|.

About the correction of our simplification process of the accumulator \verb|st|, \verb|loc| and \verb|b|, 
\begin{itemize}
\item we can add more \verb|_get_loc| or \verb|_get_st| at any positions (accepting at least a well-typed monadic expression), because we already know there is no conflict between these names and other variable names coming from the manual, thanks to the good type-checking of the previous manual. Moreover, we also know that any variable (generally leaving in the $\lambda$-calculus theory) is captured by the nearest abstraction.
\item If we add less \verb|_get_loc| or \verb|_get_st| at any positions (requiring at least one), the semantics can wrongly changed. Because the new manual type-checks correctly for ARM and SH, if for example we add less \verb|_get_loc| at a certain position, then it means necessarily that the \verb|loc| used refers wrongly to an external \verb|_get_loc|.
\end{itemize}
Hence, in any case, we hope the test validation of the Coq manual will conclude the discussion. However, by seeing the success of the current validation tests for the ARMv6 (by comparing the output of \gccSL and \SL) before the simplification and after, we have a good confidence about its accuracy. We are now going to develop the problem of certification of the simulator, the Coq manual, and its validation.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Towards a ``fast'' certified simulator}
\label{s:fast_certi}

Recall that our objective is to guarantee the correction of any program simulated by \gccSL, written in ARMv6 or SH4, and the requirement of the same state of registers for \gccSL and \SL after each instructions. 

We plan to prove this in Coq, because the sources of \SL are already and directly accessible in Coq. Thus, first we need to get a Coq representation of a \gccC code, in particular to be able to work further with the \gccSL. 
Because the \SL is Coq well-typed, we already know its termination (after any supposed number of step given). Hence, it just remains to show that its behavior is coherent with respect to \gccSL, that there is some correspondence between \SL and \gccSL. Indeed, the equivalence proof we plan to write will contain implicitly the termination property for every instruction simulated by \gccSL, as this last aim to mimic \SL. 

Now, for representing the \gccSL code in Coq and reason with, we think about using the \C type, because we suspect that its \gccC code can be easily transformed to \C. Above all, the \emph{not wrongly} behavior (in the sense of~\cite{Leroy-Compcert-CACM}) of \gccSL implies the obtaining of a \emph{not wrongly} assembler file, observationally equivalent to its source, thanks to the \ccert semantic preservation. The \C AST is also the first AST in the \ccert translation chain where the \ccert proof begins, and is thus the closest Coq AST to any \gccC.

\hspace{1ex}

Globally, we can approximate the Coq ARM/SH manual as a \emph{shallow embedding} because by definition, instructions in the Coq manual are generated using constructors belonging to the native Coq language. Similarly, the \C ARM/SH manual obtained from the \gccC source by \ccert is view as a \emph{deep embedding}, because this time, the information about the instructions are build in Coq with the \C constructor, the \C AST having been defined in Coq. The main goal is then to prove the equivalence between the \emph{deep} and \emph{shallow} embedding.

We have explained this concept of embedding with the ARM/SH manual, but it is not specially limited to, we plan indeed to generalize to the whole simulator. As the \C type is defined in Coq, the first task is, given a \gccC file, to find a way to bring up the \C AST of this \gccC file into Coq. As first application, we could then import the \gccC code of \gccSL into Coq via its \C AST, and thus we will be ready to start the correspondence proof.

\hspace{1ex}

This leads us to the section explaining how such a pretty-printer can be constructed, and more precisely, constructively realized.


\subsection{The Coq pretty-printer for \C}

Our goal is to import the \gccC code in Coq via its \C AST. We need to work with the value inhabiting the \C manual, and such, during the development process of the proof. But Coq is a language where the input and output with \outworld can not easily be done in its proper language%\footnote{Enriching Gallina with new tactics implies to modify the source of Coq.}
. At the same time, a program well-typed by the Coq type system can be extracted in a more complete programming language to interact easier with \outworld. Because the language chosen for the extraction of \ccert is OCaml, one can modify the sources of the extracted program by adding an OCaml pretty-printer, which target language is Coq ; this in order to get back the value inhabiting the \C AST of the manual. But to be less dependent of the extracting algorithm (which can perform some renaming on variables), as well as the target language of extraction (which may change in the future), we plan to redact the most achievable part of the pretty printer in Coq. Then, we will be closer to the \C AST and furthermore, we will have the possibility to evolve in a rich dependent type system framework. 
\subsubsection{Example}
In our case, the origin and the target language of the printer are Coq. The type we plan to export\footnote{``export'' or ``import'', depending the view we have as the origin language is the target language.}, \verb|AST.program fundef type| is formed with a lot of constructors. To illustrate this with a simple example, assume we have defined the following type, inspired from the sources of \ccert~:
\begin{coq}
Inductive floatsize : Type :=
  | F32: floatsize
  | F64: floatsize.

Inductive type : Type :=
  | Tvoid : type
  | Tfloat: floatsize -> type
  | Tfunction: typelist -> type -> type
with typelist : Type :=
  | Tnil : typelist
  | Tcons : type -> typelist -> typelist.

Definition ident := positive.

Record program (A : Type) : Type := mkprogram \{
  prog_funct : list (ident * A);
  prog_main : ident
\}.

Definition ast := program type.
\end{coq}
For each declarations $ty$ above, we would like to have the following printers defined in Coq~:
\begin{coq}
_floatsize : floatsize -> s
_type : type -> s
_typelist : typelist -> s
_ident : ident -> s
_program : forall A, (A -> s) -> program A -> s
_ast : ast -> s
\end{coq}
they transform $ty$ into a simple abstract datatype \verb|s|, where \verb|s| can be thought as a type similar to the well-known $string$, found in Coq or OCaml.

Dependent types are precisely useful for performing a uniform operation on all the constructor, namely by allowing us to abstract the arity of the constructor we are folding. Indeed, when seeing the declarations above, our first will is to literally copy-paste them to produce these declarations :
\begin{coq}
Definition _floatsize := __floatsize 
  | "F32" 
  | "F64".

Definition _type_ T (ty : [...]) := ty _ _floatsize
  | "Tvoid"
  | "Tfloat"
  | "Tfunction"

  | "Tnil"
  | "Tcons".
  Definition _type := _type_ _ (@__type).
  Definition _typelist := _type_ _ (@__typelist).

Definition _ident := _positive.

Definition _program \{A\} [...] := @__program [...]
  \{\{ "prog_funct" ; "prog_main" \}\}.

Definition _ast := _program _type.
\end{coq}

This can hopefully be done under the condition of having defined \verb|_INDUCTIVE| and \verb|_RECORD| as~:
\begin{coq}
  Notation "A ** n" := (A ^^ n --> A) (at level 29) : type_scope.

_INDUCTIVE : string -> forall n, s ** n
  Notation "| x" := (_INDUCTIVE x _) (at level 9).

_RECORD : forall n, vector string n -> s ** n
  Notation "\{\{ a ; .. ; b \}\}" := 
    (_RECORD _ (Vcons _ a _ .. (Vcons _ b _ (Vnil _)) ..)).
\end{coq}
where the type \verb|vector| and ``\verb|_ ^^  _ --> _|'' are respectively more deeply explained in the Coq libraries \verb|Bvector| and \verb|NaryFunctions|.
Note that the function \verb|_RECORD| can be implemented using only \verb|_INDUCTIVE|. Hence, our combinators of pretty-printing are all simulated by only one, here \verb|_INDUCTIVE|~
\footnote{In the same spirit, a {\tt Record} construction is basically seen as a notation for an {\tt Inductive} construction~\cite{Coq:manual}. % FIXME lien vers la théorie des inductifs plus précis
}.

The last ambiguity to resolve is the meaning of \verb|__floatsize|, \verb|__type|, \verb|__typelist| and \verb|__program|. In fact, it suffices us to rename them as the function \verb|floatsize_rect|, ..., \verb|program_rect|, where all the ``\verb|..._rect|'' functions are already furnished by Coq everytime a type is defined. However, for mutually recursive defined type such as \verb|type| and \verb|typelist|, we can use a function which fold completely the structure and also perform the mutually call explicitly (see the \verb|Scheme| command for this purpose). This justifies why we have regrouped above the constructors of \verb|type| and \verb|typelist| together in a unique folding function \verb|_type_|.

Finally, as \verb|_INDUCTIVE| and \verb|_RECORD| return the function type ``\verb|_ ** _|'', we need to enhance the type of our recursors \verb|__floatsize|, ..., \verb|__program| by a more powerful one, and at least \emph{convertible} to its initial type (the ``convertibility'' relation as defined in~\cite{Coq:manual}). It means that we need to write explicitly their type~:
\begin{coq}
  Notation "A [ a ; .. ; b ] -> C" := 
    (A ** a -> .. (A ** b -> C) ..) (at level 90).

Definition __floatsize {A} : A [ 0   (* F32       :           _ *)
                             ; 0 ] (* F64       :           _ *)
                           -> _ := [...].
Definition _type_ A B (f : _ -> Type) := f (
                           A [ 0   (* Tvoid     :           _ *)
                             ; 1   (* Tfloat    : _ ->      _ *)
                             ; 2   (* Tfunction : _ -> _ -> _ *)

                             ; 0   (* Tnil      :           _ *)
                             ; 2 ] (* Tcons     : _ -> _ -> _ *)
                           -> B).
Definition __type {A} : _type_ A _ (fun ty => _ -> ty) := [...].
Definition __typelist {A} : _type_ A _ (fun ty => _ -> ty) := [...].
\end{coq}
Each number corresponds exactly to the arity attended by the respective constructor.
All the informations present until now are sufficient for the type-checker to automatically deduce the remaining type. With only these declarations, our Coq library of pretty-printing considered as a functor is finished, its instantiation by a module and the definition of \verb|_INDUCTIVE| being a secondary task.
\subsubsection{Programming discussions}
\paragraph{Explicit annotations}
The counterpart of using this kind of simplified way for our printer (i.e. using the dependently form as \\ 
\verb_| "Tvoid" | "Tfloat" | "Tfunction" | "Tnil" | "Tcons"_) is highlighted by the necessity to explicitly mention the arity of each constructor. This can constitute a notable inconvenient, but in the absence of annotations, the type reconstruction becomes undecidable.
The other alternative would be to give the constructor as a more normal form ``\verb|_ -> ... -> _|''. However, the real \verb|AST.program fundef type| contains approximatively a hundred of constructors and specifying the type with a single number has rather been a good compromise.
\paragraph{Monadic embedding}
Above, we have described \verb|s| as a type similar to $string$. In fact, \verb|s| is considered abstractly during the folding of each recursors, except for \verb|_INDUCTIVE| which needs to manipulate it. Therefore, we can define it as $\verb|s| := t~\alpha$ where $t$ is a monadic type and $\alpha$ the usual value a monadic type carry with. \verb|_INDUCTIVE| being instantiated in a module separated from the pretty-printing functor, the integration remains easy.

Note that as a first consequence, because \verb|_INDUCTIVE| is the pretty-printing foundation of every constructor, we can embed inside the monadic type some extra informations, like the current indentation position depending on the depth. Moreover, the basic datatype \verb|s|, initially considered as a $string$ can now for example be replaced by a monadic buffer for efficiency.

\paragraph{Automation versus maintainability}
The process of creating a raw printing function given a type may be automated and integrated in the Coq sources. However, in the case the value we wish to import is defined with the help of the Gallina language, there may be some difficulty to print exactly the tactics used, as well as the Coq comments \verb|(* ... *)|. Hopefully, for our task of importing a \gccC data, this is not a problem because the value is rawly taken from \outworld.

The \C AST contains a lot of type information at each node (for example, every constructor of \verb|Csyntax.expr| carries a field of type \verb|Csyntax.type|), so the representation of the value printed is rather expressive. Our actual pretty-printer includes a precomputation algorithm where types are first collected and declared separately with the Coq ``\verb|Definition|''.
Before this optimization, the ARM {\tt slv6\_iss.v} file\footnote{It contains the \emph{deep} embedded manual in Coq.} size were about 52Mo. Now, it is approximatively 2Mo, and the type-checking time is thus clearly improved.

Because natural numbers are also frequently used, it can be more readable to print them using 0-9 digits, instead of their raw inductive constructor definition. Remark that if the number we print is too big, like some position of memory location, OCaml raises a \verb|Stack_overflow| with byte-code or \verb|Segmentation fault| in native version\footnote{In the same spirit, when we try to display a large number with the \coqc pretty-printer, like {\tt Check 5001.}, if it can print the number, it prints with a warning before.}, because we are in fact calling a not tail recursive function at a too nested level (and it is not specially related to natural numbers). This problem can hopefully be solved by abstracting the printing process for every failing type with a tail recursive function, the whole being instantiated with the extracted code at OCaml side.

With the extraction procedure, we have also encountered an extra $\eta$-reduction automatically performed, which gives a not well-typed OCaml code. This is resolved by manually $\eta$-expansing the offending term (appendix \ref{s:appendix_eta}).

\subsection{The creation of \aSL}
We have mentioned at the beginning that one motivation of choosing \C, as type for our work in Coq, is precisely the \ccert certification proof leading to assembler.

Thus, we are attentive at the result of every compilation steps of \gccSL with \ccert, this includes the success to obtain a \C code as well as, at the end, an assembly file.

\begin{note}
For the following, let us introduce
\begin{itemize}
\item \aC for programs for which a generated assembly file can be successfully dumped (tested at least one time), in general at the end of the compilation. For a demonstration with \compcert, see the option \verb|-dasm|.
\end{itemize}
\end{note}

\subsubsection{The context of compilation : 32 vs 64 bits}
\label{s:ctx_compil}
By definition \gccSL is GCC well-compiled, but until now, we have not precised the type of the machine used during compilation, e.g. a 32 or 64 bits processor, as well as the type of the processor that the binary will be run on, e.g. again a 32 or 64 bits (this last option can be chosen at the invocation of GCC). Hopefully, after at least four attempts, we found the same success of compilation of \gccSL on any combination of 32 or 64 bits machine, and, 32 or 64 bits processor for the target\footnote{Among the bits processor, there are of course others important characteristics describing a computer, for example, are we compiling on/for a PowerPC, IA32 or ARM machine~? Without giving complex details, we just precise that the success of these four attempts has been found on a particular same processor.}.

Like GCC, \ccert also allows us to customize the target of processor for the executable. Unlike GCC, no default choice is provided in the case the target is manually not specified, this choice becomes mandatory in \ccert. By looking at the architecture of our own 32 and 64 bits computers, among the possibilities available by \ccert, we opt to set \verb|ia32-linux| first, with the hope to extend to other processors after. But since here, cares must be taken because this simple choice can have a non-trivial influence on proofs. In particular, this \gccC program~:
\begin{humC}
#include <inttypes.h>

void main() \{
  int64_t x = 0;
\}
\end{humC}
is rejected by \ccert (if we still target the \verb|ia32-linux| processor), because 64 bits data-structures are not fully supported yet\footnote{with the current \compcert}, and this behavior does not depend on the 32 or 64 bits machine \ccert is running.

Hence, a new problem is coming : we realize that the ARM manual uses frequently 64 bits data-structures (as shown in the {\tt A4.1.81 SMLSLD} instruction). Then so does the whole \gccSL, which is, precisely at this moment, rejected by \ccert.

\subsubsection{Is \gccSL well-typed ?}
\paragraph{Going to \C to obtain \cSL}
We remarked curiously that the previous \gccC program is \ccert well accepted when the processor target is fixed to \verb|arm-linux|, and such, on a 64 bits computer only, not on a 32 bits. It means that the good support for 64 bits data-structures depends on the computer used and the processor target fixed. However, it may be surprising because the big part of the compiler is issued from Coq, a deterministic environment. Where is the error~? In fact, there is not : starting from a \gccC code, the heuristic performed to retrieve a \C code includes an external call to a preprocessor, namely ``\verb|gcc -E|''. As long as it terminates, this call is correct because by definition, the heuristic uses its proper algorithm to transform the most \hC to a \C program. Like the GCC compiler, the behavior of \verb|gcc -E| depends on the options \verb|-m32| and \verb|-m64|, which targets the processor for the executable. If absent, \verb|gcc -E| considers by default the processor currently settled. In fact, in the case of \verb|ia32-linux|, the extra option \verb|-m32| is present everytime.
Note that for \verb|arm-linux|, no options are specified, hence the previously success exhibited earlier on 64 bits is now explained.

\paragraph{Going to \aC to obtain \aSL}
Once a \C value is obtained, it is sure that the compiling process leading to assembler will terminate (this part being from Coq). However in this case, termination is not always a good result. In particular, the chain leading to assembler is written in monadic style. Types checking\footnote{We can roughly approximate the Coq conversion from \C AST to the assembler as a typing process. In particular, it may seem feasible to embed this translation in a dependent type.} are done on the fly during the conversion. When the checks fail, an exception is then returned (as terminating value).

Hopefully, in case of errors, we are clearly informed, i.e. events occur sequentially in this order : a monadic error is returned, no assembly outputs are produced, the \C value is not useful (if existing and dumped) as well as the Coq value pretty-printed from it, and \gccSL needs to be corrected.
\paragraph{Conclusion}
\subparagraph{Type-checking}
To force the compilation of \gccSL by \ccert to have a deterministic behavior, one which is independent of the machine used and to obtain an assembly file, which is here a synonym of well consistency checking, we present two possible solutions.
\begin{itemize}
\item ``Keep the program \gccSL, Modify the environment \ccert''\\
For the \verb|ia32-linux| target, inspired from \verb|arm-linux|, we tried randomly to change the heuristic from \verb|-m32| to the explicit \verb|-m64| in the preprocessing stage. Then the compilation successfully terminates ! On 32 and 64 bits computer, we can generate a 32 bits assembly file.

\item ``Modify the program \gccSL, Keep the environment \ccert''\\
Here we replace, in the generated ARM manual as well as the whole \gccSL, every 64 bits type by a record containing two 32 bits field. Usual arithmetical operations on 64 bits are then simulated in 32 bits. 

Because 32 bits data-structures are supported, the compilation process terminates. 
However, contrarly to the previous solution, it requires here to activate in \ccert the emulation of assignment between structs or unions (see the option \verb|-fstruct-assign|) \footnote{Because the activation of this option affects the \ccert heuristic, we can finally wonder if the environment has really been kept !}.
\end{itemize}

Remark that on both solutions, the option \verb|-fno-longlong| can be set because ``\verb|long long|'' types are not used.

Recall that \gccSL includes initially the generated ARM manual. Because now it compiles correctly with \ccert, it also means that the generated ARM manual is in fact a \aC source.

\subparagraph{Validation tests}
\label{s:valid_test}
After the modification performed above, we now have a single program, called \gccSL or \aSL (depending on the speaking context), compiling with target fixed at 32 and 64 bits. However to be able to think about \gccSL as a more close synonym for \aSL, we need at least to study their behavior at runtime. 

We observed unfortunately that unlike \ref{s:ctx_compil}, there exist some tests which fail now. In fact, even if the problem of 64 bits data-structures is resolved at compilation time, some arithmetical operations using 32 bits data-structures can have a not expected behavior at execution time.
More precisely, by examinating closely the situation, we remarked for instance that this \hC program~:
\begin{humC}
#include <stdio.h>

void main() \{
  int i = 32;
  printf("line 1 \%lx\textbackslash{}n", 1lu <<  i);
  printf("line 2 \%lx\textbackslash{}n", 1lu << 32);
\}
\end{humC}
which in fact belongs to the \gccC and \aC class of programs, has two surprising different behaviors by considering the executables respectively produced by GCC and \ccert (both compiling on/for \verb|ia32-linux|). Indeed, we have the following results, depending on the compiler used~:\\
\begin{tabular}{l|l|l|l}
& \verb|gcc -m64| & \verb|gcc -m32 -O0|, & \verb|gcc -m32 -O|$n$ ($n\in[$\verb|1|$; $\verb|2|$; $\verb|3|$]$) \\
&& \ccert & \\
\hline
\verb|line 1| & \verb|100000000| & \verb|1| & \verb|0| \\
\verb|line 2| & \verb|100000000| & \verb|0| & \verb|0| \\
\end{tabular} \\
(in OCaml, \verb|Int32.shift_left 1_l 32| evaluates to \verb|1_l|).

Remark that initially, starting from this \hC code included in \simsoc and \SScert~:
\begin{humC}
#include <stdio.h>

void main() \{
  int i = 32;
  printf("line 1 \%lx\textbackslash{}n", (1lu <<  i) - 1);
  printf("line 2 \%lx\textbackslash{}n", (1lu << 32) - 1);
\}
\end{humC}
we wanted to obtain \verb|ffffffff| everywhere (this was the previous behavior we had in \ref{s:ctx_compil} leading to success on validation tests) and is clearly not the results expected~:\\
\begin{tabular}{l|l|l}
& \verb|gcc -m64|, & \verb|gcc -m32 -O0|, \\
& \verb|gcc -m32 -O|$n$ ($n\in[$\verb|1|$; $\verb|2|$; $\verb|3|$]$)& \ccert \\
\hline
\verb|line 1| & \verb|ffffffff| & \verb|0| \\
\verb|line 2| & \verb|ffffffff| & \verb|ffffffff| \\
\end{tabular} \\

Finally, we have fixed this error to get \verb|ffffffff| everywhere : this problem using 32 bits data-structures can be easily avoided by using explicitly the deterministic aforementioned operations on 64 bits data-structures, instead of 32.

Now, validation tests succeed on both \gccSL and \aSL.
%\item Except this 64 bits data-structures not supported in \ccert, we have not encountered others difficult problems during the compilation.

\begin{fact}
However their possible different behavior at runtime, \gccSL, \cSL, and \aSL come from an initial same source.
\end{fact}

\subsection{The behavior of \aSL, towards \lSL}
\subsubsection{Does \aSL terminate ?}
We are now one step closer to invocate the main \ccert theorem, which predicts completely the behavior of the assembly file produced from \aSL. 
\begin{itemize}
\item Because \aSL has in fact been existencially produced, it means the compilation process has lead to a successful monadic value. This is a condition needed first by the main \ccert theorem. Due to the success to get an assembly file, we conjecture this condition is easy to prove in Coq, in particular using some ``\verb|vm_compute|''. 
\item Besides that hypothesis, the main \ccert theorem takes precisely as parameter the behavior we estimate for the source. Indeed, it is our task to give a bet on a behavior $b$ the initial \aSL has (at \C AST production time), and to show that its execution really follows $b$. Then, if $b$ is not classified in particular as a \emph{wrong} behavior, \ccert will answer us that the assembly executable has surely the behavior $b$.
\end{itemize}

Remark that some reorganizations have been done in the last version of \ccert. Before \compcert, the main theorem of correction needs to take exactly these two hypothesis before proceeding further. In \compcert, the idea remains the same but more lemmas are provided to help proving that the \C program will \emph{progress safely} at each steps. In particular, if we suppose the evaluation being deterministic, analyzing the \C program within the big-step semantic suffices to deduce the behavior of the assembly. To simply outline our reasonning, we will approximate in the following the ``\emph{progress safety}'' notion by ``\emph{not wrong}'' and will not emphasize too much on the evaluation strategy.

\begin{note}
We will use the abbreviation :
\begin{itemize}
\item \lC for programs which can be successfully transformed to an assembly file with a certified compiler preserving its original semantic (and preserving at least from the \C big-step semantic). Moreover, the behavior of the initial source is required to be proved \emph{not wrong}.
\end{itemize}
\end{note}

\begin{ex}
This \aC code is not a \lC program :
\begin{humC}
int main(int _) \{
  return 0;
\}
\end{humC}
because the type of the main function (called from \outworld) is not of the form $unit\rightarrow int$. Thus it initially goes wrong by definition.
\end{ex}

Due to the supposed Turing-completeness of the ARM programming language, we think that \aSL does not \emph{terminate} and precisely that it is characterized by the \emph{reactive divergence} behavior (which at the same time does not belong to the \emph{going wrong} behavior, as specified in \ccert).

\paragraph{The behaving proof on a simple program}
Because \aSL contains a lot of lines, we tried first to prove the termination of this simple \aC program~:
\begin{humC}
main() \{
  int x = 2;
  int y = 3;
  return x + y;
\}
\end{humC}
in particular by using mainly the \verb|eapply| tactic. However, as long as the proof grows up, this tactic takes abnormally a too long time to succeed, in particular in front of a huge term. During that time, we were thinking instead to an other way to solve the behaving problem. This leads to the part explaining the shortcut found.
\paragraph{\lSL obtained with a meta consideration on Coq}
The example above shows us that proving the behavior, of an apparently simple program, is susceptible to take a long time. We also remark that this task is finally maybe not a priority, especially in the case we can easier prove first there is some kind of equivalence between this program and a Coq program.

Finally, we can wonder if we can begin first with the equivalence between \aSL and \SL (at the \C value reached time), than trying to obtain a \lSL by betting on a behavior $b$. In fact, with the former proceeding, we would have an equivalence between the deep AST and functions in Coq. It means we will have implicitely the proof of the non wrong-behavior of this deep AST, due to the supposed non wrong-behavior of the Coq system.
Then we will know at the meta level that \aSL can not have a \emph{wrong} behavior, even if a particular $b$ has not yet been exhibited in Coq at that time, a condition needed for the creation of \lSL. 

In conclusion, if we choose first to prove a kind of equivalence between \aSL and \SL, and succeed, we will have meta proved the non wrong behavior for \aSL. 
 By extending the reasoning further, we would be sure that the semantic of the initial source has been preserved to assembler. Moreover, we conjecture all this reasoning can yet be formally proved in a type system not different than at Coq level, by starting to exhibit a particular behavior $b$ from one side of the equivalence, from the \aSL, or maybe the \SL side...

%On both cases, during the establisment of the two proofs, we are informed if we encounter some not well-formed part in \aSL (part that need to be changed).

\subsubsection{Future work : the equivalence proof}
\paragraph{Coq $\Longrightarrow$ \lC~?}
Initially, before the creation of any simulator in \simsoc, remark that to get at the end at least one \lC simulator, we could initially take another approach, that is to start with a complete simulator in Coq (a similar one to \simsoc, not only \aSL), then to modify and equip Coq with a constructive extraction procedure into \lC (like ML, Haskell or Scheme). This solution is feasible, because \lC has a formal semantic (since the \C AST), and rather general as the extraction process can be applied to any Coq program. However, as the project \simsoc has historically been established before \SScert, the organization of the \gccC code behind \simsoc is currently rather detailed and complex now, compared to the existing one at Coq side. Moreover, in term of efficiency, it seems not trivial how to perform in Coq the optimization necessary for setting good performances in SimSoC. Hence, the extraction from Coq is interesting, but we are also interested to know which large part of this \gccC simulator can automatically be translated in Coq and which can not.

\paragraph{Coq $\Longleftarrow$ \lC~?}
The problem we are focusing are more open than only oriented from Coq to \lC. For example, even if the Coq manual is usually considered as the model of reference, for validation, tests are usually performed in \gccSL and \aSL due to performance issue. Indeed, we are interested in a semantical preservative way to report back modifications from \lC side to Coq. 

More generally, it may be difficult to prove the semantical preservation from a Turing-complete language to Coq. Nevertheless, we conjecture the \aC manual is only formed with recursive functions. If we omit this semantical preservation requirement, the question remains important for proving the correction of an arbitrary \lC code. Given a \hC code, under which conditions can one retrieve a ``similar'' Coq code, attesting its good termination ? 

\paragraph{ML $\Longrightarrow$ (Coq $\Longleftrightarrow$ \lC) ?}

In~\ref{s:simgendef} and the SH part, we have explained the automatic importation of the ARM/SH manual by \simgen into \gccC, and later \aC. By following our reasoning of translating \lC into some form of Coq code, it is legitimate to ask if we can also translate the \aC manual in Coq directly. However, the generation of the \aC manual being an automatic process, we had found convenient to use the existing code to produce the Coq manual in the same OCaml environment. Then, \simgen generates both the \aC manual and the Coq manual. By catching the reasoning in this context, the intention to prove the equivalence between these \emph{two} outputs of a \emph{single} program (here \simgen) from a \emph{single} input is less astonishing. 

For this particular case, the generation of \aC being automatic, instead of proving directly the output's equivalence, we can think about proving the good generation starting from the \simgen AST. Indeed, by approximating the raw Coq source into its AST (the Coq AST), as well as approximating the \aC source into the \C AST, 
\begin{itemize}
\item on one hand we have an ML function translating from \simgen AST to Coq AST,
\item on the other hand, we have another ML function from \simgen AST to \C AST.
\end{itemize} 
As we think they can easily be translated in Coq, the problem of good equivalence between the Coq manual and the \aC manual can be simplified to the problem of building a couple given a particular \simgen AST, i.e writing a Coq function of type : \\
\verb!simgen_AST -> { (man_coq, man_C) | man_coq <~> man_C }!. Of course, the equivalence function ``\verb|<~>|'' still remains to be defined, but constructing this function-proof may be easier than working directly on the output. Hence, this solution can figure as a potential candidate to explore.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{s:concl}

We have obtained a SH4 formal model using the same algorithm as was employed for the ARMv6, by automatic extraction of pseudo-formal descriptions and automatic conversion to Coq syntax. The merge into \SScert was performed modularly with functors in order to facilitate the integration of future processors.

The importation of a \C value via our Coq pretty-printer being ready, the next step is to prove the equivalence between the existing Coq model and the \aC model. After this, we will extend our proof to the complete part of the processor and system simulator : code specialization, dynamic recompilation on the host machine...

Finally, we hope to plug our certified simulator after the \ccert chain leading to assembler source. In contrast with the bootstrapping process which aim to create a higher language than existing, this would terminate the certifying chain preserving the semantics of high-level software to safe execution on hardware.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{alpha}
\bibliography{t}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\section{Appendix}
\subsection{Errors in the OCaml extracted code}
For the following, starting from a well-typed Coq program, the extraction gives wrong \ocaml files. This behaviour has been seen with at least the version trunk \coqv~and the \coqc (in the examples, we will present code written in style \coqv).
%we are going to submit a bug report after further tests if needed, in particular with the current ``trunk'' development version.
\subsubsection{The optimized $\eta$-simplification}
\label{s:appendix_eta}
\verb|http://www.lix.polytechnique.fr/coq/bugs/show_bug.cgi?id=2570|\\
This extracted implementation from a Coq code~:
\begin{ml}
open Datatypes
open List
open Vector

type __ = Obj.t

(** val to_list0 : nat -> 'a1 t -> 'a1 list **)

let to_list0 n = function
| Coq_nil -> Datatypes.Coq_nil
| Coq_cons (x, n0, t0) -> Datatypes.Coq_cons (x, Datatypes.Coq_nil)

(** val u1 :
    nat -> (__ -> nat -> __ t -> __ list) -> 'a1 t -> 'a3 list -> 'a2 t ->
    'a1 -> 'a1 **)

let u1 n to_list1 sep xs surr =
  let v_to_list = to_list0 n in
  let c = fun s l -> combine (v_to_list s) l in
  List.fold_left (fun x x0 -> x) (c sep (c surr xs))
\end{ml}
is accepted by the OCaml type-checker but it does not match its extracted interface, because \verb|u1| has a too general type. This can be resolved by manually replacing \verb|let v_to_list = to_list0 n| by \verb|let v_to_list v = to_list0 n v|.

\paragraph{Others possible solutions}
\begin{itemize}
\item
Note that in the original Coq code~:
\begin{coq}
Require Import Vector.
Require Import List.

Definition to_list0 : forall A n,
  Vector.t A n -> \{ _ : list A | True \} :=
  fun A _ v => @exist (list A) (fun _ => True) 
    match v with 
    | Vector.cons x _ _ => List.cons x List.nil
    | Vector.nil => List.nil
    end I.

Definition u1 : forall M N L n
  (to_list1 : forall A n,
  Vector.t A n -> \{ _ : list A | True \})
  (sep : Vector.t M n)
  (xs : list L)
  (surr : Vector.t N n),
  M -> M.
  intros until 4;
  pose (v_to_list A v := let (l, _) := to_list0 A n v in l);
  pose (c := fun B n s l => @List.combine _ B (v_to_list n s) l);
  refine (List.fold_left _ (c _ _ sep (c _ _ surr xs)));
  auto with *.
Defined.
\end{coq}
if we replace, \verb|to_list0| by \verb|to_list1| in \verb|u1|, the extracted implementation matches correctly its interface~:
\begin{ml}
let u1 n to_list0 sep xs surr =
  let v_to_list = to_list0 __ n in
  let c = fun s l -> combine (v_to_list s) l in
  List.fold_left (fun x x0 -> x)
    (Obj.magic (fun _ _ s l -> c s l) __ __ sep
      (Obj.magic (fun _ _ s l -> c s l) __ __ surr xs))
\end{ml}

\item
Instead of doing a manual $\eta$-expansion, we can disable the optimization responsible of this error in Coq with~:
\begin{coq}
Set Extraction Flag 494.
\end{coq}
(see the file {\tt coq\_svn\_\coqv/plugins/extraction/table.ml} for others possibilities with numbers).
Then, we have this well-accepted code, which does not use \verb|Obj.magic|~:
\begin{ml}
let u1 n to_list1 sep xs surr =
  let v_to_list = fun _ v -> to_list0 n v in
  let c = fun _ _ s l -> combine (v_to_list __ s) l in
  List.fold_left (fun x x0 -> x) (c __ __ sep (c __ __ surr xs))
\end{ml}
\end{itemize}

\paragraph{Localization in the source}
In {\tt coq\_svn\_\coqv[...]mlutil.ml}, the $\eta$-reduction performed in the function \verb|kill_dummy| does not perform an $\eta$-reduction test to avoid a not generalizable \verb|'_a|. At the time of writing, it is not sure that this test may or not be done in a similar way as {\tt coq\_svn\_\coqv[...]extraction.ml}.
Remark also, even if it has not been tested, that we may factorize the part under the case \verb|MLletin| in \verb|kill_dummy| with the \verb|MLletin| part in \verb|kill_dummy_hd| by abstracting what is necessary.
\subsubsection{The default inlining on singleton type definition}
\label{s:appendix_singl}
During some code writing, when we encounter this message : \coqkernel, we renamed the inductive with a new name. However, this leads to an error when compiling the extracted code.
For instance, even with :
\begin{coq}
Set Extraction Flag 0.
Unset Extraction AutoInline.
\end{coq}
there is an implicit simplification during extraction time on this code~:
\begin{coq}
Module Type SINGLE.
  Parameter single : Type.
End SINGLE.

Module S.
  Inductive single_ := One (*| Two*).
  Definition single := single_.
End S.

Module Make (S : SINGLE).
End Make.

Module M := Make S.
\end{coq}
which gives an OCaml code waiting for the field \verb|single|, as OCaml responded to us : ``required but not provided''.
\end{document}
